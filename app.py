import streamlit as st
import pandas as pd
import numpy as np
from scipy.spatial.distance import cdist
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="Outil de Maillage Interne", layout="wide")

st.title("üîó Outil d'Optimisation du Maillage Interne")

# Import du diagramme HTML (obligatoire)
st.subheader("üìÇ Importer votre diagramme de clusters (HTML export√© depuis Screaming Frog)")
uploaded_html = st.file_uploader("Importer un fichier HTML de diagramme de clusters", type=["html"])

if uploaded_html:
    custom_html = uploaded_html.read().decode("utf-8")
    st.components.v1.html(custom_html, height=800, scrolling=True)
    
    with st.expander("‚ÑπÔ∏è Explication du diagramme de clusters"):
        st.markdown("""
        <div style="background-color: #f9f9f9; padding: 1.5em; border-radius: 10px; border: 1px solid #ccc; font-family: Arial, sans-serif;">
        <h3>üìä √Ä propos du Diagramme de Clusters de Contenu</h3>
        <p>Ce diagramme repr√©sente une vue simplifi√©e du contenu de votre site web, bas√© sur les URL explor√©es. Chaque point correspond √† une page, et les points proches entre eux partagent des similarit√©s dans leur contenu.</p>
        
        <h4>Comment fonctionne ce diagramme ?</h4>
        <ul>
          <li><strong>Embeddings :</strong> Chaque page re√ßoit un vecteur num√©rique repr√©sentant sa s√©mantique.</li>
          <li><strong>√âchantillonnage :</strong> Un sous-ensemble d'URL est affich√© pour la lisibilit√©.</li>
          <li><strong>R√©duction de dimensions :</strong> Les donn√©es sont compress√©es en 2D pour visualisation.</li>
          <li><strong>Clustering :</strong> Les pages sont regroup√©es en clusters color√©s selon leur similarit√©.</li>
        </ul>
        <h4>üìå √Ä propos des axes :</h4>
        <p>Les axes ne repr√©sentent pas une mesure pr√©cise. Ils servent √† positionner les pages selon leur proximit√© s√©mantique.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Import CSV (URLs, clusters, coordonn√©es, mots-cl√©s)
    st.subheader("üìÑ Importer vos donn√©es d'URL (CSV)")
    data = st.file_uploader("Importer un fichier CSV avec URLs, clusters, coordonn√©es et mots-cl√©s", type=['csv'])
    
    if data:
        df = pd.read_csv(data)
        st.write("Aper√ßu des donn√©es :", df.head())

        # Recherche de mots-cl√©s
        keyword = st.text_input("üîç Rechercher un mot-cl√©")
        if keyword:
            results = df[df['keyword'].str.contains(keyword, case=False, na=False)]
            st.write(f"R√©sultats pour le mot-cl√© : {keyword}")
            st.dataframe(results)

        # D√©tection de cannibalisation
        st.subheader("üö® D√©tection de cannibalisation")
        distance_threshold = st.slider("Seuil de proximit√© (plus bas = plus strict)", 0.0, 10.0, 1.0)
        if st.button("Analyser la cannibalisation"):
            coords = df[['x', 'y']].values
            dist_matrix = cdist(coords, coords)
            risks = []
            for i in range(len(df)):
                for j in range(i + 1, len(df)):
                    if dist_matrix[i, j] < distance_threshold and df.loc[i, 'cluster'] != df.loc[j, 'cluster']:
                        risks.append((df.loc[i, 'url'], df.loc[j, 'url'], dist_matrix[i, j]))
            if risks:
                st.write("Risques d√©tect√©s :")
                st.table(risks)
            else:
                st.write("Aucun risque d√©tect√©.")

        # Recommandations de maillage
        st.subheader("üîó Recommandations de Maillage")
        url_input = st.text_input("Entrez une URL pour obtenir des suggestions")
        if url_input:
            if url_input in df['url'].values:
                idx = df[df['url'] == url_input].index[0]
                target_coords = df.loc[idx, ['x', 'y']].values.reshape(1, -1)
                dist = cdist(target_coords, df[['x', 'y']].values).flatten()
                df['distance'] = dist
                nearby = df[(df['url'] != url_input)].sort_values('distance').head(10)

                st.write("üëâ Pages vers lesquelles cette page pourrait faire des liens (sortants) :")
                st.dataframe(nearby[['url', 'keyword', 'distance']])

                st.write("üëâ Pages qui pourraient faire un lien vers cette page (entrants) :")
                incoming = nearby.copy()
                st.dataframe(incoming[['url', 'keyword', 'distance']])
            else:
                st.error("L'URL saisie n'existe pas dans le fichier import√©.")

        # Analyse s√©mantique optionnelle
        st.subheader("üìÑ Analyse s√©mantique (optionnelle)")
        if 'keyword' in df.columns:
            vectorizer = TfidfVectorizer()
            tfidf_matrix = vectorizer.fit_transform(df['keyword'].fillna(''))
            cosine_sim = cosine_similarity(tfidf_matrix)
            st.write("Similitude s√©mantique entre les pages (extrait 5x5) :")
            st.dataframe(pd.DataFrame(cosine_sim[:5, :5], index=df['url'].head(5), columns=df['url'].head(5)))
    else:
        st.info("Veuillez importer un fichier CSV pour analyser les donn√©es d'URL.")
else:
    st.info("üí° Veuillez importer un fichier HTML pour afficher votre diagramme de clusters.")
  
